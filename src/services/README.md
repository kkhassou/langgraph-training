# Services Layer - é«˜ãƒ¬ãƒ™ãƒ«ãªçµ±åˆã‚µãƒ¼ãƒ“ã‚¹

ã“ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¯ã€è¤‡æ•°ã®ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚„ã‚¤ãƒ³ãƒ•ãƒ©å±¤ã‚’çµ±åˆã™ã‚‹é«˜ãƒ¬ãƒ™ãƒ«ãªã‚µãƒ¼ãƒ“ã‚¹ã‚’å«ã¿ã¾ã™ã€‚

## ğŸ“Š ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«ãŠã‘ã‚‹ä½ç½®ã¥ã‘

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Workflows Layer               â”‚  â† å®Ÿè¡Œå¯èƒ½ãªã‚°ãƒ©ãƒ•
â”‚   (workflows/atomic/composite)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“ ä½¿ã†
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Nodes Layer                   â”‚  â† LangGraphãƒãƒ¼ãƒ‰å®šç¾©
â”‚   (nodes/primitives/composites) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“ ä½¿ã†
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Providers Layer               â”‚  â† æŠ½è±¡ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
â”‚   (core/providers, providers/)  â”‚     (LLM, RAGãªã©)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“ ä½¿ã†
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Services Layer â­ ã“ã“ï¼       â”‚  â† çµ±åˆã‚µãƒ¼ãƒ“ã‚¹
â”‚   (services/rag/mcp/document)   â”‚     (è¤‡æ•°ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’çµ±åˆ)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“ ä½¿ã†
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Infrastructure Layer          â”‚  â† ä½ãƒ¬ãƒ™ãƒ«å®Ÿè£…
â”‚   (embeddings, vector_stores)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¯ Services å±¤ã®æ–°ã—ã„å½¹å‰²ï¼ˆãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°å¾Œï¼‰

### âš ï¸ é‡è¦ãªå¤‰æ›´

**LLM Service Layer ã¯å»ƒæ­¢ã•ã‚Œã¾ã—ãŸã€‚** LLMé–¢é€£ã®æ©Ÿèƒ½ã¯ Provider Layer ã«çµ±åˆã•ã‚Œã¾ã—ãŸã€‚

### ç¾åœ¨ã®å½¹å‰²

Services Layer ã¯ä»¥ä¸‹ã® **çµ±åˆã‚µãƒ¼ãƒ“ã‚¹** ã®ã¿ã‚’æä¾›ã—ã¾ã™ï¼š

1. **RAG Service** - embeddingç”Ÿæˆã€æ¤œç´¢ã€LLMç”Ÿæˆã‚’çµ±åˆ
2. **MCP Service** - MCPé–¢é€£ã®çµ±åˆæ©Ÿèƒ½ï¼ˆä»Šå¾Œï¼‰
3. **Document Service** - ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå‡¦ç†ã®çµ±åˆæ©Ÿèƒ½ï¼ˆä»Šå¾Œï¼‰

### åˆ¤æ–­åŸºæº–

**ã€Œã“ã®æ©Ÿèƒ½ã¯è¤‡æ•°ã®ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚„ã‚¤ãƒ³ãƒ•ãƒ©å±¤ã‚’çµ±åˆã™ã‚‹ã‹ï¼Ÿã€** â†’ YES ãªã‚‰ Services

## ğŸ“ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ï¼ˆãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°å¾Œï¼‰

```
src/services/
â”‚
â”œâ”€â”€ llm/                    # âŒ å»ƒæ­¢ â†’ src/core/providers/llm ã¸ç§»è¡Œ
â”‚   â””â”€â”€ __init__.py         # å»ƒæ­¢ã®ãŠçŸ¥ã‚‰ã›ã¨ç§»è¡Œã‚¬ã‚¤ãƒ‰
â”‚
â”œâ”€â”€ rag/                    # âœ… çµ±åˆã‚µãƒ¼ãƒ“ã‚¹ã¨ã—ã¦æ®‹ã™
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ rag_service.py      # Embedding + VectorStore + LLM ã®çµ±åˆ
â”‚
â”œâ”€â”€ mcp/                    # âœ… MCPçµ±åˆã‚µãƒ¼ãƒ“ã‚¹
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ slack.py
â”‚   â”œâ”€â”€ github.py
â”‚   â””â”€â”€ google/...
â”‚
â””â”€â”€ document/               # âœ… ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå‡¦ç†ã‚µãƒ¼ãƒ“ã‚¹
    â”œâ”€â”€ __init__.py
    â””â”€â”€ document_service.py
```

## ğŸ’¡ ä½¿ç”¨ä¾‹

### âš ï¸ LLM Services ã¯å»ƒæ­¢ã•ã‚Œã¾ã—ãŸ

**æ—§ã‚³ãƒ¼ãƒ‰ï¼ˆå»ƒæ­¢ï¼‰:**
```python
from src.services.llm.gemini_service import GeminiService

# âŒ ã“ã®æ–¹æ³•ã¯ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„
advice = await GeminiService.generate(prompt=prompt, temperature=0.7)
```

**æ–°ã—ã„ã‚³ãƒ¼ãƒ‰ï¼ˆæ¨å¥¨ï¼‰:**
```python
from src.core.factory import ProviderFactory

# âœ… Providerãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ä½¿ç”¨
provider = ProviderFactory.get_default_llm_provider()
advice = await provider.generate(prompt=prompt, temperature=0.7)
```

### RAG Servicesï¼ˆçµ±åˆã‚µãƒ¼ãƒ“ã‚¹ï¼‰

#### RAGã‚¯ã‚¨ãƒªã®å®Ÿè¡Œ

```python
from src.services.rag.rag_service import RAGService

# RAGã‚µãƒ¼ãƒ“ã‚¹ã‚’åˆæœŸåŒ–
service = RAGService()

# ã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œï¼ˆembeddingç”Ÿæˆã€æ¤œç´¢ã€LLMç”Ÿæˆã‚’çµ±åˆï¼‰
result = await service.query(
    query="æ©Ÿæ¢°å­¦ç¿’ã¨ã¯ï¼Ÿ",
    collection_name="tech_docs",
    top_k=5
)

print(result.answer)  # LLMã®å¿œç­”
print(result.retrieved_documents)  # æ¤œç´¢çµæœ
```

#### ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ç™»éŒ²

```python
from src.services.rag.rag_service import RAGService

service = RAGService()

documents = [
    {
        "id": "doc1",
        "content": "æ©Ÿæ¢°å­¦ç¿’ã¯...",
        "metadata": {"source": "textbook"}
    }
]

result = await service.ingest_documents(
    documents=documents,
    collection_name="tech_docs"
)
```

## ğŸ“ LLM Provider API ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ï¼ˆç§»è¡Œå…ˆï¼‰

### âš ï¸ LLMé–¢é€£ã¯ Provider Layer ã¸ç§»è¡Œã—ã¾ã—ãŸ

LLMæ©Ÿèƒ½ã¯ `src.core.providers.llm.LLMProvider` ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã«çµ±åˆã•ã‚Œã¦ã„ã¾ã™ã€‚

**æ–°ã—ã„ä½¿ã„æ–¹:**

```python
from src.core.factory import ProviderFactory

# Providerã‚’å–å¾—
provider = ProviderFactory.get_default_llm_provider()

# ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
text = await provider.generate(
    prompt="ã“ã‚“ã«ã¡ã¯",
    temperature=0.7
)

# JSONç”Ÿæˆ
from pydantic import BaseModel

class TodoItem(BaseModel):
    title: str
    priority: str

result = await provider.generate_json(
    prompt="TODOã‚’ä½œæˆã—ã¦ãã ã•ã„",
    schema=TodoItem,
    temperature=0.7
)

# ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä»˜ãç”Ÿæˆ
answer = await provider.generate_with_context(
    user_query="æ©Ÿæ¢°å­¦ç¿’ã¨ã¯ï¼Ÿ",
    context="æ©Ÿæ¢°å­¦ç¿’ã¯...",
    system_instruction="å°‚é–€å®¶ã¨ã—ã¦å›ç­”ã—ã¦ãã ã•ã„",
    temperature=0.7
)
```

è©³ç´°ã¯ä»¥ä¸‹ã‚’å‚ç…§ï¼š
- `src/core/providers/llm.py` - LLMProviderã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
- `src/providers/llm/gemini.py` - Geminiå®Ÿè£…
- `src/core/factory.py` - ProviderFactory

## ğŸ“ RAG Service API ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹

### `RAGService.query()`

RAGã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œï¼ˆembeddingç”Ÿæˆã€æ¤œç´¢ã€LLMç”Ÿæˆã‚’çµ±åˆï¼‰

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:

- `query: str` - ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•
- `collection_name: str = "default_collection"` - æ¤œç´¢å¯¾è±¡ã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
- `top_k: int = 5` - å–å¾—ã™ã‚‹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°
- `include_embedding: bool = False` - åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’å«ã‚ã‚‹ã‹
- `temperature: float = 0.7` - LLMã®æ¸©åº¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

**æˆ»ã‚Šå€¤**: `RAGResult` - RAGå®Ÿè¡Œçµæœ

### `RAGService.ingest_documents()`

ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’Vector Storeã«ç™»éŒ²

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:

- `documents: List[Dict[str, Any]]` - ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ãƒªã‚¹ãƒˆ
- `collection_name: str = "default_collection"` - ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å

**æˆ»ã‚Šå€¤**: `Dict[str, Any]` - ç™»éŒ²çµæœ

## ğŸ ãƒ¡ãƒªãƒƒãƒˆï¼ˆProvider ãƒ‘ã‚¿ãƒ¼ãƒ³ã¸ã®ç§»è¡Œå¾Œï¼‰

### Beforeï¼ˆç›´æ¥APIå‘¼ã³å‡ºã—ï¼‰

```python
# å„ãƒãƒ¼ãƒ‰ã§36è¡Œã®é‡è¤‡ã‚³ãƒ¼ãƒ‰
class TodoAdvisorNode:
    def __init__(self):
        self.api_key = os.getenv("GEMINI_API_KEY")
        genai.configure(api_key=self.api_key)
        self.model = genai.GenerativeModel('gemini-2.0-flash-exp')

    async def execute(self, input_data):
        response = self.model.generate_content(prompt)
        advice = response.text.strip()
        # ...
```

### Afterï¼ˆProvider ãƒ‘ã‚¿ãƒ¼ãƒ³ + ä¾å­˜æ€§æ³¨å…¥ï¼‰

```python
# ã‚·ãƒ³ãƒ—ãƒ«ã§æ‹¡å¼µå¯èƒ½
class TodoAdvisorNode:
    def __init__(self, provider: Optional[LLMProvider] = None):
        self.provider = provider or ProviderFactory.get_default_llm_provider()
    
    async def execute(self, input_data):
        prompt = self._create_prompt(input_data["todo"])
        advice = await self.provider.generate(prompt, temperature=0.7)
        return NodeResult(success=True, data={"advice": advice})
```

**çµæœ**: 
- ã‚³ãƒ¼ãƒ‰ãŒ 60%å‰Šæ¸›
- ãƒ†ã‚¹ãƒˆæ™‚ã«ãƒ¢ãƒƒã‚¯æ³¨å…¥ãŒå¯èƒ½
- ç•°ãªã‚‹LLMã¸ã®åˆ‡ã‚Šæ›¿ãˆãŒå®¹æ˜“
- ä¿å®ˆæ€§ãƒ»æ‹¡å¼µæ€§ãŒå¤§å¹…ã«å‘ä¸Šï¼

## ğŸš€ ä»Šå¾Œã®æ‹¡å¼µ

### æ–°ã—ã„LLM Providerã®è¿½åŠ ï¼ˆProvider Layerï¼‰

```python
# src/providers/llm/openai.py
from src.core.providers.llm import LLMProvider

class OpenAIProvider(LLMProvider):
    async def generate(self, prompt: str, **kwargs) -> str:
        # OpenAIå®Ÿè£…
        ...

# ç™»éŒ²
from src.core.factory import ProviderFactory
ProviderFactory.register_llm_provider("openai", OpenAIProvider)
```

### RAGçµ±åˆã‚µãƒ¼ãƒ“ã‚¹ã®å¼·åŒ–

```python
# src/services/rag/advanced_rag_service.py
class AdvancedRAGService(RAGService):
    """ã‚ˆã‚Šé«˜åº¦ãªæ¤œç´¢ãƒ»ç”Ÿæˆæ©Ÿèƒ½ã‚’æŒã¤RAGã‚µãƒ¼ãƒ“ã‚¹"""
    async def query_with_reranking(self, query: str, **kwargs):
        # ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°æ©Ÿèƒ½ã‚’è¿½åŠ 
        ...
```

### MCPçµ±åˆã‚µãƒ¼ãƒ“ã‚¹

```python
# src/services/mcp/unified_mcp_service.py
class UnifiedMCPService:
    """è¤‡æ•°ã®MCPã‚µãƒ¼ãƒ“ã‚¹ã‚’çµ±åˆ"""
    async def execute_workflow(self, workflow: Dict[str, Any]):
        # Slack + GitHub + Google ã®çµ±åˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
        ...
```

## ğŸ“š é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

- [ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°å®Œäº†ãƒ¬ãƒãƒ¼ãƒˆ](../../REFACTORING_COMPLETE.md)
- [Providerå±¤ã®è¨­è¨ˆ](../../PHASE1_COMPLETE.md)
- [Factory ãƒ‘ã‚¿ãƒ¼ãƒ³](../../PHASE4_COMPLETE.md)
- [ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¦‚è¦](../../æ‹¡å¼µæ€§ã‚’è€ƒæ…®ã—ãŸã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒˆã¸ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹.md)
