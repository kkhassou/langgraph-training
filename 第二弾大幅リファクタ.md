# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®æ”¹å–„ææ¡ˆã‚’è€ƒãˆã‚‹
_Exported on 2025/11/22 at 23:52:08 JST from Cursor (2.1.19)_

---

**User**

ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ã€ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã§ã€è‰²ã€…ãªå¤–éƒ¨ãƒ„ãƒ¼ãƒ«ã‚‚ä½¿ã£ã¦ã€

æ§˜ã€…ãªè¤‡é›‘ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’LangGraphã®ãƒãƒ¼ãƒ‰ã‚’çµ„ã¿ç«‹ã¦ã¦ã€é–‹ç™ºã™ã‚‹ã®ã‚’ãªã‚‹ã¹ãç°¡å˜ã«ã§ãã‚‹ã‚ˆã†ã«ã—ãŸã„ã¨ã„ã†ç›®çš„ã§ä½œã£ã¦ã„ã¾ã™ã€‚

ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚„å€‹åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿®æ­£ã‚‚å«ã‚ã¦ã€

ã©ã®ã‚ˆã†ãªæ”¹å–„ãŒã§ãã‚‹ã‹è€ƒãˆã¦ãã ã•ã„

---

**Cursor**

ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®å…¨ä½“åƒã‚’ç†è§£ã™ã‚‹ãŸã‚ã«ã€ä¸»è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ç¢ºèªã•ã›ã¦ã„ãŸã ãã¾ã™ã€‚

ã„ãã¤ã‹ã®ä¸»è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã•ã‚‰ã«ç¢ºèªã•ã›ã¦ã„ãŸã ãã¾ã™ã€‚

ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®è©³ç´°ã‚’ç¢ºèªã•ã›ã¦ã„ãŸã ãã¾ã—ãŸã€‚éå¸¸ã«é«˜ã„ãƒ¬ãƒ™ãƒ«ã§æ•´ç†ã•ã‚Œã¦ãŠã‚Šã€95/100ç‚¹ã®è©•ä¾¡ã‚‚ç´å¾—ã§ã™ã€‚ç¾çŠ¶ã‚’è¸ã¾ãˆã¦ã€ã•ã‚‰ãªã‚‹æ”¹å–„ææ¡ˆã‚’åŒ…æ‹¬çš„ã«ã¾ã¨ã‚ã¾ã™ã€‚

ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®å…¨ä½“åƒã‚’æŠŠæ¡ã—ã¾ã—ãŸã€‚ä»¥ä¸‹ã€åŒ…æ‹¬çš„ãªæ”¹å–„ææ¡ˆã‚’ã¾ã¨ã‚ã¾ã™ã€‚

# ğŸ¯ LangGraph Training ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ - åŒ…æ‹¬çš„ãªæ”¹å–„ææ¡ˆ

## ğŸ“Š ç¾çŠ¶è©•ä¾¡

**ç¾åœ¨ã®ã‚¹ã‚³ã‚¢: 95/100ç‚¹** â­â­â­â­â­

ã™ã§ã«éå¸¸ã«é«˜ã„ãƒ¬ãƒ™ãƒ«ã§æ•´ç†ã•ã‚Œã¦ãŠã‚Šã€ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºã‚°ãƒ¬ãƒ¼ãƒ‰ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æŒã£ã¦ã„ã¾ã™ã€‚

### ä¸»ãªå¼·ã¿
- âœ… å®Œç’§ãªDIã‚³ãƒ³ãƒ†ãƒŠå®Ÿè£…ï¼ˆdependency-injectorï¼‰
- âœ… æ˜ç¢ºãª3å±¤ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
- âœ… ProvideræŠ½è±¡åŒ–ã«ã‚ˆã‚‹æ‹¡å¼µæ€§
- âœ… ã‚«ã‚¹ã‚¿ãƒ ä¾‹å¤–éšå±¤
- âœ… pydantic-settings ã«ã‚ˆã‚‹å‹å®‰å…¨ãªè¨­å®šç®¡ç†

---

## ğŸš€ å„ªå…ˆåº¦åˆ¥ã®æ”¹å–„ææ¡ˆ

### ã€é«˜å„ªå…ˆåº¦ã€‘å³åº§ã«å®Ÿæ–½ã™ã¹ãæ”¹å–„

#### 1. **Nodeså±¤ã®ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°** ğŸ”¥
**å•é¡Œ**: `src/nodes/integrations/mcp/` ã«å…¨ã‚µãƒ¼ãƒ“ã‚¹ãŒæ··åœ¨
**ææ¡ˆ**: READMEã«è¨˜è¼‰ã•ã‚ŒãŸæ–°æ§‹é€ ã¸ã®ç§»è¡Œ

```python
# ç¾åœ¨
src/nodes/integrations/mcp/
  â”œâ”€â”€ slack.py
  â”œâ”€â”€ github.py
  â””â”€â”€ ... (12ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ··åœ¨)

# æ”¹å–„å¾Œ
src/nodes/integrations/
  â”œâ”€â”€ slack/
  â”‚   â”œâ”€â”€ __init__.py
  â”‚   â””â”€â”€ node.py
  â”œâ”€â”€ github/
  â”‚   â”œâ”€â”€ __init__.py
  â”‚   â””â”€â”€ node.py
  â””â”€â”€ google/
      â”œâ”€â”€ gmail/
      â”‚   â”œâ”€â”€ __init__.py
      â”‚   â””â”€â”€ node.py
      â””â”€â”€ calendar/
          â”œâ”€â”€ __init__.py
          â””â”€â”€ node.py
```

**ãƒ¡ãƒªãƒƒãƒˆ**:
- ã‚µãƒ¼ãƒ“ã‚¹ã”ã¨ã®ç‹¬ç«‹æ€§å‘ä¸Š
- MCPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæ§‹é€ ã¨ã®çµ±ä¸€
- æ‹¡å¼µæ€§ã®å¤§å¹…å‘ä¸Š
- ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®æ•´ç†ãŒå®¹æ˜“

**å®Ÿè£…æ‰‹é †**:
```bash
# 1. æ–°ã—ã„ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã‚’ä½œæˆ
mkdir -p src/nodes/primitives/{llm,rag,document}
mkdir -p src/nodes/composites/{todo,workflow_builders}
mkdir -p src/nodes/integrations/{slack,github,notion}
mkdir -p src/nodes/integrations/google/{gmail,calendar,docs,sheets,slides}

# 2. ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ®µéšçš„ã«ç§»è¡Œï¼ˆ1ã‚µãƒ¼ãƒ“ã‚¹ãšã¤ï¼‰
# 3. ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‘ã‚¹ã‚’æ›´æ–°
# 4. ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã—ã¦ç¢ºèª
# 5. æ—§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
```

---

#### 2. **çµ±åˆãƒ†ã‚¹ãƒˆã®è¿½åŠ ** ğŸ§ª
**å•é¡Œ**: ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆã¯å……å®Ÿã—ã¦ã„ã‚‹ãŒã€E2Eãƒ†ã‚¹ãƒˆãŒä¸è¶³

**ææ¡ˆ**: ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã®ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆã‚’è¿½åŠ 

```python
# tests/integration/test_e2e_workflows.py
import pytest
from src.workflows.atomic.chat import ChatWorkflow, ChatInput
from src.workflows.composite.intelligent_chat.chain_of_thought import (
    ChainOfThoughtWorkflow, ChainOfThoughtInput
)

@pytest.mark.integration
@pytest.mark.asyncio
async def test_chat_workflow_e2e():
    """ãƒãƒ£ãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒ†ã‚¹ãƒˆ"""
    workflow = ChatWorkflow()
    result = await workflow.run(
        ChatInput(message="Python ã®ç‰¹å¾´ã‚’3ã¤æŒ™ã’ã¦ãã ã•ã„")
    )
    
    assert result.success is True
    assert len(result.response) > 50
    assert "Python" in result.response


@pytest.mark.integration
@pytest.mark.asyncio
async def test_chain_of_thought_e2e():
    """è¤‡åˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒ†ã‚¹ãƒˆ"""
    workflow = ChainOfThoughtWorkflow()
    result = await workflow.run(
        ChainOfThoughtInput(
            question="ãªãœç©ºã¯é’ã„ã®ã§ã™ã‹ï¼Ÿ",
            steps=3
        )
    )
    
    assert result.success is True
    assert len(result.reasoning_steps) == 3
    assert result.final_answer


@pytest.mark.integration
@pytest.mark.asyncio
async def test_workflow_error_handling():
    """ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®ãƒ†ã‚¹ãƒˆ"""
    workflow = ChatWorkflow()
    result = await workflow.run(
        ChatInput(message="", temperature=2.0)  # ç„¡åŠ¹ãªå…¥åŠ›
    )
    
    assert result.success is False
    assert result.error_message
```

**ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ç›®æ¨™**:
```bash
pytest --cov=src --cov-report=html --cov-report=term

# ç›®æ¨™ã‚«ãƒãƒ¬ãƒƒã‚¸
# - Providerå±¤: 90%ä»¥ä¸Š
# - Nodeå±¤: 85%ä»¥ä¸Š
# - Workflowå±¤: 80%ä»¥ä¸Š
# - Serviceå±¤: 85%ä»¥ä¸Š
```

---

#### 3. **æ§‹é€ åŒ–ãƒ­ã‚®ãƒ³ã‚°ã®å¼·åŒ–** ğŸ“Š
**å•é¡Œ**: ãƒ­ã‚®ãƒ³ã‚°ã¯å®Ÿè£…ã•ã‚Œã¦ã„ã‚‹ãŒã€JSONå½¢å¼ã§ã®æ§‹é€ åŒ–ãŒä¸å®Œå…¨

**ææ¡ˆ**: å®Œå…¨ãªæ§‹é€ åŒ–ãƒ­ã‚®ãƒ³ã‚°ã®å®Ÿè£…

```python
# src/core/logging_config.pyï¼ˆæ”¹å–„ç‰ˆï¼‰
import logging
import json
from datetime import datetime
from typing import Any, Dict
from contextvars import ContextVar

# ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå¤‰æ•°
request_id_var: ContextVar[str] = ContextVar('request_id', default='')
user_id_var: ContextVar[str] = ContextVar('user_id', default='')
workflow_id_var: ContextVar[str] = ContextVar('workflow_id', default='')

class StructuredLogger:
    """æ§‹é€ åŒ–ãƒ­ã‚®ãƒ³ã‚°ã®ãƒ©ãƒƒãƒ‘ãƒ¼"""
    
    def __init__(self, logger: logging.Logger):
        self.logger = logger
    
    def _add_context(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã‚’è¿½åŠ """
        return {
            **data,
            "timestamp": datetime.utcnow().isoformat(),
            "request_id": request_id_var.get(),
            "user_id": user_id_var.get(),
            "workflow_id": workflow_id_var.get(),
        }
    
    def info(self, message: str, **kwargs):
        """INFO ãƒ¬ãƒ™ãƒ«ãƒ­ã‚°"""
        data = self._add_context({"message": message, "level": "INFO", **kwargs})
        self.logger.info(json.dumps(data, ensure_ascii=False))
    
    def error(self, message: str, exc_info=None, **kwargs):
        """ERROR ãƒ¬ãƒ™ãƒ«ãƒ­ã‚°"""
        data = self._add_context({
            "message": message,
            "level": "ERROR",
            **kwargs
        })
        if exc_info:
            data["exception"] = str(exc_info)
        self.logger.error(json.dumps(data, ensure_ascii=False))
    
    def workflow_start(self, workflow_name: str, input_data: Dict[str, Any]):
        """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼é–‹å§‹ãƒ­ã‚°"""
        self.info(
            "Workflow started",
            workflow_name=workflow_name,
            input_keys=list(input_data.keys()),
            event_type="workflow_start"
        )
    
    def workflow_end(self, workflow_name: str, duration: float, success: bool):
        """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Œäº†ãƒ­ã‚°"""
        self.info(
            "Workflow completed",
            workflow_name=workflow_name,
            duration_ms=duration * 1000,
            success=success,
            event_type="workflow_end"
        )
    
    def node_execute(self, node_name: str, node_type: str, duration: float):
        """ãƒãƒ¼ãƒ‰å®Ÿè¡Œãƒ­ã‚°"""
        self.info(
            "Node executed",
            node_name=node_name,
            node_type=node_type,
            duration_ms=duration * 1000,
            event_type="node_execute"
        )

def get_structured_logger(name: str) -> StructuredLogger:
    """æ§‹é€ åŒ–ãƒ­ã‚¬ãƒ¼ã‚’å–å¾—"""
    return StructuredLogger(logging.getLogger(name))
```

**ä½¿ç”¨ä¾‹**:
```python
from src.core.logging_config import get_structured_logger, workflow_id_var

logger = get_structured_logger(__name__)

async def run_workflow(input_data):
    workflow_id_var.set(str(uuid.uuid4()))
    
    logger.workflow_start("chat_workflow", input_data.dict())
    
    start_time = time.time()
    try:
        result = await execute()
        duration = time.time() - start_time
        logger.workflow_end("chat_workflow", duration, success=True)
        return result
    except Exception as e:
        duration = time.time() - start_time
        logger.workflow_end("chat_workflow", duration, success=False)
        logger.error("Workflow failed", exc_info=e)
        raise
```

---

### ã€ä¸­å„ªå…ˆåº¦ã€‘æ®µéšçš„ã«å®Ÿæ–½ã™ã‚‹æ”¹å–„

#### 4. **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–** âš¡

##### 4.1 LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®ã‚³ãƒã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ¼ãƒ«
```python
# src/providers/llm/gemini.pyï¼ˆæ”¹å–„ç‰ˆï¼‰
from typing import Optional, AsyncIterator
import asyncio
from contextlib import asynccontextmanager

class GeminiProvider(LLMProvider):
    """ã‚³ãƒã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ¼ãƒªãƒ³ã‚°å¯¾å¿œã®Geminiãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼"""
    
    def __init__(
        self,
        api_key: str,
        model: str = "gemini-2.0-flash-exp",
        max_concurrent_requests: int = 5,  # åŒæ™‚ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°åˆ¶é™
        rate_limit_per_minute: int = 60     # ãƒ¬ãƒ¼ãƒˆåˆ¶é™
    ):
        self.api_key = api_key
        self.model = model
        self._semaphore = asyncio.Semaphore(max_concurrent_requests)
        self._rate_limiter = RateLimiter(rate_limit_per_minute)
        genai.configure(api_key=api_key)
    
    @asynccontextmanager
    async def _acquire_slot(self) -> AsyncIterator[None]:
        """ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¹ãƒ­ãƒƒãƒˆã‚’å–å¾—"""
        async with self._semaphore:
            await self._rate_limiter.acquire()
            yield
    
    async def generate(self, prompt: str, **kwargs) -> str:
        """ãƒ¬ãƒ¼ãƒˆåˆ¶é™ä»˜ãã®ç”Ÿæˆ"""
        async with self._acquire_slot():
            # æ—¢å­˜ã®ç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯
            ...

class RateLimiter:
    """ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ¬ãƒ¼ãƒˆåˆ¶é™å™¨"""
    
    def __init__(self, requests_per_minute: int):
        self.requests_per_minute = requests_per_minute
        self.requests = []
    
    async def acquire(self):
        """ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¹ãƒ­ãƒƒãƒˆã‚’å–å¾—ï¼ˆå¿…è¦ãªã‚‰å¾…æ©Ÿï¼‰"""
        now = time.time()
        # 1åˆ†ä»¥ä¸Šå‰ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å‰Šé™¤
        self.requests = [r for r in self.requests if now - r < 60]
        
        if len(self.requests) >= self.requests_per_minute:
            # å¾…æ©Ÿæ™‚é–“ã‚’è¨ˆç®—
            oldest = self.requests[0]
            wait_time = 60 - (now - oldest)
            if wait_time > 0:
                await asyncio.sleep(wait_time)
        
        self.requests.append(now)
```

##### 4.2 RAGæ¤œç´¢çµæœã®ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°
```python
# src/infrastructure/cache/rag_cache.pyï¼ˆæ–°è¦ï¼‰
from typing import Optional, List, Dict, Any
from functools import lru_cache
import hashlib
import json

class RAGCache:
    """RAGæ¤œç´¢çµæœã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥"""
    
    def __init__(self, max_size: int = 1000, ttl: int = 3600):
        self.max_size = max_size
        self.ttl = ttl
        self._cache: Dict[str, tuple[float, List[Dict[str, Any]]]] = {}
    
    def _generate_key(self, query: str, collection: str, top_k: int) -> str:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ã‚’ç”Ÿæˆ"""
        data = f"{query}|{collection}|{top_k}"
        return hashlib.md5(data.encode()).hexdigest()
    
    def get(
        self,
        query: str,
        collection: str,
        top_k: int
    ) -> Optional[List[Dict[str, Any]]]:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—"""
        key = self._generate_key(query, collection, top_k)
        
        if key in self._cache:
            timestamp, results = self._cache[key]
            # TTLãƒã‚§ãƒƒã‚¯
            if time.time() - timestamp < self.ttl:
                return results
            else:
                del self._cache[key]
        
        return None
    
    def set(
        self,
        query: str,
        collection: str,
        top_k: int,
        results: List[Dict[str, Any]]
    ):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜"""
        key = self._generate_key(query, collection, top_k)
        
        # ã‚µã‚¤ã‚ºåˆ¶é™ãƒã‚§ãƒƒã‚¯
        if len(self._cache) >= self.max_size:
            # æœ€ã‚‚å¤ã„ã‚¨ãƒ³ãƒˆãƒªã‚’å‰Šé™¤
            oldest_key = min(self._cache.keys(), key=lambda k: self._cache[k][0])
            del self._cache[oldest_key]
        
        self._cache[key] = (time.time(), results)
```

---

#### 5. **ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã‚·ã‚¹ãƒ†ãƒ ã®å¼·åŒ–** ğŸ”Œ

**ææ¡ˆ**: ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã®è‡ªå‹•æ¤œå‡ºã¨å‹•çš„ãƒ­ãƒ¼ãƒ‰

```python
# src/core/plugin_loader.pyï¼ˆæ”¹å–„ç‰ˆï¼‰
from typing import Dict, Type, List
import importlib
import pkgutil
from pathlib import Path

class PluginDiscovery:
    """ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã®è‡ªå‹•æ¤œå‡º"""
    
    def __init__(self, plugin_dir: str = "src/plugins"):
        self.plugin_dir = Path(plugin_dir)
    
    def discover_plugins(self) -> List[Dict[str, Any]]:
        """ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ã‚¹ã‚­ãƒ£ãƒ³ã—ã¦å…¨ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã‚’ç™ºè¦‹"""
        plugins = []
        
        if not self.plugin_dir.exists():
            return plugins
        
        for item in self.plugin_dir.iterdir():
            if item.is_dir() and not item.name.startswith('_'):
                plugin_info = self._load_plugin_info(item)
                if plugin_info:
                    plugins.append(plugin_info)
        
        return plugins
    
    def _load_plugin_info(self, plugin_path: Path) -> Optional[Dict[str, Any]]:
        """ãƒ—ãƒ©ã‚°ã‚¤ãƒ³æƒ…å ±ã‚’èª­ã¿è¾¼ã‚€"""
        manifest_path = plugin_path / "plugin.json"
        
        if not manifest_path.exists():
            return None
        
        with open(manifest_path) as f:
            manifest = json.load(f)
        
        return {
            "name": manifest["name"],
            "version": manifest["version"],
            "type": manifest["type"],  # "llm", "rag", "node", etc.
            "entry_point": manifest["entry_point"],
            "path": plugin_path
        }
    
    def load_plugin(self, plugin_info: Dict[str, Any]) -> Any:
        """ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã‚’å‹•çš„ã«ãƒ­ãƒ¼ãƒ‰"""
        module_path = f"src.plugins.{plugin_info['name']}.{plugin_info['entry_point']}"
        
        try:
            module = importlib.import_module(module_path)
            return module
        except ImportError as e:
            logger.error(f"Failed to load plugin {plugin_info['name']}: {e}")
            return None

# ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆã®ä¾‹
# src/plugins/custom_llm/plugin.json
{
    "name": "custom_llm",
    "version": "1.0.0",
    "type": "llm",
    "entry_point": "provider",
    "description": "ã‚«ã‚¹ã‚¿ãƒ LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼",
    "author": "Your Name",
    "dependencies": ["openai>=1.0.0"]
}
```

---

#### 6. **OpenAPIä»•æ§˜ã®æ”¹å–„** ğŸ“˜

**ææ¡ˆ**: ã‚ˆã‚Šè©³ç´°ãªAPIä»•æ§˜ã¨ã‚µãƒ³ãƒ—ãƒ«ã®è¿½åŠ 

```python
# src/main.pyï¼ˆæ”¹å–„ç‰ˆï¼‰
from fastapi import FastAPI
from fastapi.openapi.utils import get_openapi

app = FastAPI(
    title="LangGraph Training API",
    description="""
    LangGraphãƒ™ãƒ¼ã‚¹ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ 
    
    ## ä¸»ãªæ©Ÿèƒ½
    
    * **Atomic Workflows**: å˜ä¸€æ©Ÿèƒ½ã®åŸºæœ¬ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
    * **Composite Workflows**: è¤‡æ•°ã®Atomicã‚’çµ„ã¿åˆã‚ã›ãŸé«˜åº¦ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
    * **Node Management**: å€‹åˆ¥ãƒãƒ¼ãƒ‰ã®å®Ÿè¡Œã¨ç®¡ç†
    
    ## ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
    
    3å±¤æ§‹é€ ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼š
    - Atomic Layer: æœ€å°å®Ÿè¡Œå˜ä½
    - Composite Layer: Atomicã®çµ„ã¿åˆã‚ã›
    - Orchestration Layer: Compositeã®çµ±åˆï¼ˆä»Šå¾Œå®Ÿè£…ï¼‰
    """,
    version="2.0.0",
    contact={
        "name": "é–‹ç™ºãƒãƒ¼ãƒ ",
        "email": "team@example.com",
    },
    license_info={
        "name": "MIT",
    },
)

def custom_openapi():
    """ã‚«ã‚¹ã‚¿ãƒ OpenAPIã‚¹ã‚­ãƒ¼ãƒ"""
    if app.openapi_schema:
        return app.openapi_schema
    
    openapi_schema = get_openapi(
        title=app.title,
        version=app.version,
        description=app.description,
        routes=app.routes,
    )
    
    # ã‚¿ã‚°ã®èª¬æ˜ã‚’è¿½åŠ 
    openapi_schema["tags"] = [
        {
            "name": "workflows",
            "description": "ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"
        },
        {
            "name": "nodes",
            "description": "ãƒãƒ¼ãƒ‰ç®¡ç†ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"
        },
        {
            "name": "health",
            "description": "ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"
        }
    ]
    
    # ã‚µãƒ¼ãƒãƒ¼æƒ…å ±ã‚’è¿½åŠ 
    openapi_schema["servers"] = [
        {"url": "http://localhost:8000", "description": "é–‹ç™ºç’°å¢ƒ"},
        {"url": "https://api.example.com", "description": "æœ¬ç•ªç’°å¢ƒ"}
    ]
    
    app.openapi_schema = openapi_schema
    return app.openapi_schema

app.openapi = custom_openapi
```

---

### ã€ä½å„ªå…ˆåº¦ã€‘å°†æ¥çš„ãªæ”¹å–„

#### 7. **Workflowãƒ“ãƒ«ãƒ€ãƒ¼ UI** ğŸ¨
**ææ¡ˆ**: ãƒ–ãƒ©ã‚¦ã‚¶ãƒ™ãƒ¼ã‚¹ã®ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚¨ãƒ‡ã‚£ã‚¿

```
src/
â”œâ”€â”€ frontend/              # æ–°è¦è¿½åŠ 
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ WorkflowCanvas.vue
â”‚   â”‚   â”œâ”€â”€ NodePalette.vue
â”‚   â”‚   â””â”€â”€ PropertyPanel.vue
â”‚   â”œâ”€â”€ stores/
â”‚   â”‚   â””â”€â”€ workflowStore.ts
â”‚   â””â”€â”€ App.vue
```

#### 8. **ç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰** ğŸ“ˆ
**ææ¡ˆ**: Grafana + Prometheusãƒ™ãƒ¼ã‚¹ã®ç›£è¦–

```yaml
# docker-compose.monitoring.yml
version: '3.8'
services:
  prometheus:
    image: prom/prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
  
  grafana:
    image: grafana/grafana
    ports:
      - "3000:3000"
    volumes:
      - ./grafana/dashboards:/etc/grafana/provisioning/dashboards
```

#### 9. **ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†** ğŸ“¦
```python
# src/workflows/versioning.pyï¼ˆæ–°è¦ï¼‰
from typing import Dict, Any
from datetime import datetime

class WorkflowVersion:
    """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†"""
    
    def __init__(self, workflow_id: str, version: str):
        self.workflow_id = workflow_id
        self.version = version
        self.created_at = datetime.utcnow()
        self.definition: Dict[str, Any] = {}
    
    def export(self) -> Dict[str, Any]:
        """ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        return {
            "workflow_id": self.workflow_id,
            "version": self.version,
            "created_at": self.created_at.isoformat(),
            "definition": self.definition
        }
    
    @classmethod
    def from_export(cls, data: Dict[str, Any]) -> "WorkflowVersion":
        """ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å¾©å…ƒ"""
        version = cls(data["workflow_id"], data["version"])
        version.definition = data["definition"]
        return version
```

---

## ğŸ“‹ å®Ÿè£…ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—

### Phase 1ï¼ˆ1-2é€±é–“ï¼‰- å³åº§ã«å®Ÿæ–½
- [x] Nodeså±¤ã®ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°è¨ˆç”»ã®ç¢ºå®š
- [ ] æ–°ã—ã„ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã®ä½œæˆ
- [ ] 1-2ã‚µãƒ¼ãƒ“ã‚¹ã®ç§»è¡Œï¼ˆä¾‹: Slack, GitHubï¼‰
- [ ] çµ±åˆãƒ†ã‚¹ãƒˆã®åŸºæœ¬æ§‹é€ ä½œæˆ

### Phase 2ï¼ˆ2-3é€±é–“ï¼‰- æ®µéšçš„å®Ÿæ–½
- [ ] æ®‹ã‚Šã®Nodesã®ç§»è¡Œå®Œäº†
- [ ] çµ±åˆãƒ†ã‚¹ãƒˆã®æ‹¡å……ï¼ˆã‚«ãƒãƒ¬ãƒƒã‚¸80%ä»¥ä¸Šï¼‰
- [ ] æ§‹é€ åŒ–ãƒ­ã‚®ãƒ³ã‚°ã®å®Œå…¨å®Ÿè£…
- [ ] ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ï¼‰

### Phase 3ï¼ˆ1ãƒ¶æœˆï¼‰- æ©Ÿèƒ½æ‹¡å¼µ
- [ ] ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã®è‡ªå‹•æ¤œå‡ºæ©Ÿèƒ½
- [ ] OpenAPIä»•æ§˜ã®æ”¹å–„
- [ ] ç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã®æ§‹ç¯‰

### Phase 4ï¼ˆå°†æ¥ï¼‰- é«˜åº¦ãªæ©Ÿèƒ½
- [ ] Workflowãƒ“ãƒ«ãƒ€ãƒ¼ UI
- [ ] ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†
- [ ] ãƒãƒ«ãƒãƒ†ãƒŠãƒ³ãƒˆå¯¾å¿œ

---

## ğŸ¯ ã¾ã¨ã‚

ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯æ—¢ã«éå¸¸ã«é«˜ã„ãƒ¬ãƒ™ãƒ«ã«ã‚ã‚Šã¾ã™ãŒã€ä»¥ä¸‹ã®ç‚¹ã§ã•ã‚‰ã«æ”¹å–„ã§ãã¾ã™ï¼š

### æœ€å„ªå…ˆäº‹é …ï¼ˆä»Šã™ãå®Ÿæ–½ï¼‰
1. **Nodeså±¤ã®ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°** - æ‹¡å¼µæ€§ã¨ä¿å®ˆæ€§ã®å¤§å¹…å‘ä¸Š
2. **çµ±åˆãƒ†ã‚¹ãƒˆã®è¿½åŠ ** - å“è³ªä¿è¨¼ã®å¼·åŒ–
3. **æ§‹é€ åŒ–ãƒ­ã‚®ãƒ³ã‚°** - æœ¬ç•ªé‹ç”¨ã§ã®å•é¡Œè¿½è·¡

### æ®µéšçš„ã«å®Ÿæ–½
4. **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–** - ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã®å‘ä¸Š
5. **ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã‚·ã‚¹ãƒ†ãƒ å¼·åŒ–** - æ‹¡å¼µæ€§ã®ã•ã‚‰ãªã‚‹å‘ä¸Š
6. **OpenAPIä»•æ§˜ã®æ”¹å–„** - é–‹ç™ºè€…ä½“é¨“ã®å‘ä¸Š

ã“ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¯**æ¥­ç•Œæ¨™æº–ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹**ã‚’å®Ÿè£…ã—ã¦ãŠã‚Šã€ã“ã‚Œã‚‰ã®æ”¹å–„ã«ã‚ˆã‚Š**100ç‚¹æº€ç‚¹**ã«è¿‘ã¥ã‘ã‚‹ã“ã¨ãŒã§ãã¾ã™ï¼

```python
# ç¾åœ¨
src/nodes/integrations/mcp/
  â”œâ”€â”€ slack.py
  â”œâ”€â”€ github.py
  â””â”€â”€ ... (12ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ··åœ¨)

# æ”¹å–„å¾Œ
src/nodes/integrations/
  â”œâ”€â”€ slack/
  â”‚   â”œâ”€â”€ __init__.py
  â”‚   â””â”€â”€ node.py
  â”œâ”€â”€ github/
  â”‚   â”œâ”€â”€ __init__.py
  â”‚   â””â”€â”€ node.py
  â””â”€â”€ google/
      â”œâ”€â”€ gmail/
      â”‚   â”œâ”€â”€ __init__.py
      â”‚   â””â”€â”€ node.py
      â””â”€â”€ calendar/
          â”œâ”€â”€ __init__.py
          â””â”€â”€ node.py
```

```shellscript
# 1. æ–°ã—ã„ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã‚’ä½œæˆ
mkdir -p src/nodes/primitives/{llm,rag,document}
mkdir -p src/nodes/composites/{todo,workflow_builders}
mkdir -p src/nodes/integrations/{slack,github,notion}
mkdir -p src/nodes/integrations/google/{gmail,calendar,docs,sheets,slides}

# 2. ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ®µéšçš„ã«ç§»è¡Œï¼ˆ1ã‚µãƒ¼ãƒ“ã‚¹ãšã¤ï¼‰
# 3. ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‘ã‚¹ã‚’æ›´æ–°
# 4. ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã—ã¦ç¢ºèª
# 5. æ—§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
```

```python
# tests/integration/test_e2e_workflows.py
import pytest
from src.workflows.atomic.chat import ChatWorkflow, ChatInput
from src.workflows.composite.intelligent_chat.chain_of_thought import (
    ChainOfThoughtWorkflow, ChainOfThoughtInput
)

@pytest.mark.integration
@pytest.mark.asyncio
async def test_chat_workflow_e2e():
    """ãƒãƒ£ãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒ†ã‚¹ãƒˆ"""
    workflow = ChatWorkflow()
    result = await workflow.run(
        ChatInput(message="Python ã®ç‰¹å¾´ã‚’3ã¤æŒ™ã’ã¦ãã ã•ã„")
    )
    
    assert result.success is True
    assert len(result.response) > 50
    assert "Python" in result.response


@pytest.mark.integration
@pytest.mark.asyncio
async def test_chain_of_thought_e2e():
    """è¤‡åˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒ†ã‚¹ãƒˆ"""
    workflow = ChainOfThoughtWorkflow()
    result = await workflow.run(
        ChainOfThoughtInput(
            question="ãªãœç©ºã¯é’ã„ã®ã§ã™ã‹ï¼Ÿ",
            steps=3
        )
    )
    
    assert result.success is True
    assert len(result.reasoning_steps) == 3
    assert result.final_answer


@pytest.mark.integration
@pytest.mark.asyncio
async def test_workflow_error_handling():
    """ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®ãƒ†ã‚¹ãƒˆ"""
    workflow = ChatWorkflow()
    result = await workflow.run(
        ChatInput(message="", temperature=2.0)  # ç„¡åŠ¹ãªå…¥åŠ›
    )
    
    assert result.success is False
    assert result.error_message
```

```shellscript
pytest --cov=src --cov-report=html --cov-report=term

# ç›®æ¨™ã‚«ãƒãƒ¬ãƒƒã‚¸
# - Providerå±¤: 90%ä»¥ä¸Š
# - Nodeå±¤: 85%ä»¥ä¸Š
# - Workflowå±¤: 80%ä»¥ä¸Š
# - Serviceå±¤: 85%ä»¥ä¸Š
```

```python
# src/core/logging_config.pyï¼ˆæ”¹å–„ç‰ˆï¼‰
import logging
import json
from datetime import datetime
from typing import Any, Dict
from contextvars import ContextVar

# ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå¤‰æ•°
request_id_var: ContextVar[str] = ContextVar('request_id', default='')
user_id_var: ContextVar[str] = ContextVar('user_id', default='')
workflow_id_var: ContextVar[str] = ContextVar('workflow_id', default='')

class StructuredLogger:
    """æ§‹é€ åŒ–ãƒ­ã‚®ãƒ³ã‚°ã®ãƒ©ãƒƒãƒ‘ãƒ¼"""
    
    def __init__(self, logger: logging.Logger):
        self.logger = logger
    
    def _add_context(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã‚’è¿½åŠ """
        return {
            **data,
            "timestamp": datetime.utcnow().isoformat(),
            "request_id": request_id_var.get(),
            "user_id": user_id_var.get(),
            "workflow_id": workflow_id_var.get(),
        }
    
    def info(self, message: str, **kwargs):
        """INFO ãƒ¬ãƒ™ãƒ«ãƒ­ã‚°"""
        data = self._add_context({"message": message, "level": "INFO", **kwargs})
        self.logger.info(json.dumps(data, ensure_ascii=False))
    
    def error(self, message: str, exc_info=None, **kwargs):
        """ERROR ãƒ¬ãƒ™ãƒ«ãƒ­ã‚°"""
        data = self._add_context({
            "message": message,
            "level": "ERROR",
            **kwargs
        })
        if exc_info:
            data["exception"] = str(exc_info)
        self.logger.error(json.dumps(data, ensure_ascii=False))
    
    def workflow_start(self, workflow_name: str, input_data: Dict[str, Any]):
        """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼é–‹å§‹ãƒ­ã‚°"""
        self.info(
            "Workflow started",
            workflow_name=workflow_name,
            input_keys=list(input_data.keys()),
            event_type="workflow_start"
        )
    
    def workflow_end(self, workflow_name: str, duration: float, success: bool):
        """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Œäº†ãƒ­ã‚°"""
        self.info(
            "Workflow completed",
            workflow_name=workflow_name,
            duration_ms=duration * 1000,
            success=success,
            event_type="workflow_end"
        )
    
    def node_execute(self, node_name: str, node_type: str, duration: float):
        """ãƒãƒ¼ãƒ‰å®Ÿè¡Œãƒ­ã‚°"""
        self.info(
            "Node executed",
            node_name=node_name,
            node_type=node_type,
            duration_ms=duration * 1000,
            event_type="node_execute"
        )

def get_structured_logger(name: str) -> StructuredLogger:
    """æ§‹é€ åŒ–ãƒ­ã‚¬ãƒ¼ã‚’å–å¾—"""
    return StructuredLogger(logging.getLogger(name))
```

```python
from src.core.logging_config import get_structured_logger, workflow_id_var

logger = get_structured_logger(__name__)

async def run_workflow(input_data):
    workflow_id_var.set(str(uuid.uuid4()))
    
    logger.workflow_start("chat_workflow", input_data.dict())
    
    start_time = time.time()
    try:
        result = await execute()
        duration = time.time() - start_time
        logger.workflow_end("chat_workflow", duration, success=True)
        return result
    except Exception as e:
        duration = time.time() - start_time
        logger.workflow_end("chat_workflow", duration, success=False)
        logger.error("Workflow failed", exc_info=e)
        raise
```

```python
# src/providers/llm/gemini.pyï¼ˆæ”¹å–„ç‰ˆï¼‰
from typing import Optional, AsyncIterator
import asyncio
from contextlib import asynccontextmanager

class GeminiProvider(LLMProvider):
    """ã‚³ãƒã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ¼ãƒªãƒ³ã‚°å¯¾å¿œã®Geminiãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼"""
    
    def __init__(
        self,
        api_key: str,
        model: str = "gemini-2.0-flash-exp",
        max_concurrent_requests: int = 5,  # åŒæ™‚ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°åˆ¶é™
        rate_limit_per_minute: int = 60     # ãƒ¬ãƒ¼ãƒˆåˆ¶é™
    ):
        self.api_key = api_key
        self.model = model
        self._semaphore = asyncio.Semaphore(max_concurrent_requests)
        self._rate_limiter = RateLimiter(rate_limit_per_minute)
        genai.configure(api_key=api_key)
    
    @asynccontextmanager
    async def _acquire_slot(self) -> AsyncIterator[None]:
        """ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¹ãƒ­ãƒƒãƒˆã‚’å–å¾—"""
        async with self._semaphore:
            await self._rate_limiter.acquire()
            yield
    
    async def generate(self, prompt: str, **kwargs) -> str:
        """ãƒ¬ãƒ¼ãƒˆåˆ¶é™ä»˜ãã®ç”Ÿæˆ"""
        async with self._acquire_slot():
            # æ—¢å­˜ã®ç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯
            ...

class RateLimiter:
    """ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ¬ãƒ¼ãƒˆåˆ¶é™å™¨"""
    
    def __init__(self, requests_per_minute: int):
        self.requests_per_minute = requests_per_minute
        self.requests = []
    
    async def acquire(self):
        """ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¹ãƒ­ãƒƒãƒˆã‚’å–å¾—ï¼ˆå¿…è¦ãªã‚‰å¾…æ©Ÿï¼‰"""
        now = time.time()
        # 1åˆ†ä»¥ä¸Šå‰ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å‰Šé™¤
        self.requests = [r for r in self.requests if now - r < 60]
        
        if len(self.requests) >= self.requests_per_minute:
            # å¾…æ©Ÿæ™‚é–“ã‚’è¨ˆç®—
            oldest = self.requests[0]
            wait_time = 60 - (now - oldest)
            if wait_time > 0:
                await asyncio.sleep(wait_time)
        
        self.requests.append(now)
```

```python
# src/infrastructure/cache/rag_cache.pyï¼ˆæ–°è¦ï¼‰
from typing import Optional, List, Dict, Any
from functools import lru_cache
import hashlib
import json

class RAGCache:
    """RAGæ¤œç´¢çµæœã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥"""
    
    def __init__(self, max_size: int = 1000, ttl: int = 3600):
        self.max_size = max_size
        self.ttl = ttl
        self._cache: Dict[str, tuple[float, List[Dict[str, Any]]]] = {}
    
    def _generate_key(self, query: str, collection: str, top_k: int) -> str:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ã‚’ç”Ÿæˆ"""
        data = f"{query}|{collection}|{top_k}"
        return hashlib.md5(data.encode()).hexdigest()
    
    def get(
        self,
        query: str,
        collection: str,
        top_k: int
    ) -> Optional[List[Dict[str, Any]]]:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—"""
        key = self._generate_key(query, collection, top_k)
        
        if key in self._cache:
            timestamp, results = self._cache[key]
            # TTLãƒã‚§ãƒƒã‚¯
            if time.time() - timestamp < self.ttl:
                return results
            else:
                del self._cache[key]
        
        return None
    
    def set(
        self,
        query: str,
        collection: str,
        top_k: int,
        results: List[Dict[str, Any]]
    ):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜"""
        key = self._generate_key(query, collection, top_k)
        
        # ã‚µã‚¤ã‚ºåˆ¶é™ãƒã‚§ãƒƒã‚¯
        if len(self._cache) >= self.max_size:
            # æœ€ã‚‚å¤ã„ã‚¨ãƒ³ãƒˆãƒªã‚’å‰Šé™¤
            oldest_key = min(self._cache.keys(), key=lambda k: self._cache[k][0])
            del self._cache[oldest_key]
        
        self._cache[key] = (time.time(), results)
```

```python
# src/core/plugin_loader.pyï¼ˆæ”¹å–„ç‰ˆï¼‰
from typing import Dict, Type, List
import importlib
import pkgutil
from pathlib import Path

class PluginDiscovery:
    """ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã®è‡ªå‹•æ¤œå‡º"""
    
    def __init__(self, plugin_dir: str = "src/plugins"):
        self.plugin_dir = Path(plugin_dir)
    
    def discover_plugins(self) -> List[Dict[str, Any]]:
        """ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ã‚¹ã‚­ãƒ£ãƒ³ã—ã¦å…¨ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã‚’ç™ºè¦‹"""
        plugins = []
        
        if not self.plugin_dir.exists():
            return plugins
        
        for item in self.plugin_dir.iterdir():
            if item.is_dir() and not item.name.startswith('_'):
                plugin_info = self._load_plugin_info(item)
                if plugin_info:
                    plugins.append(plugin_info)
        
        return plugins
    
    def _load_plugin_info(self, plugin_path: Path) -> Optional[Dict[str, Any]]:
        """ãƒ—ãƒ©ã‚°ã‚¤ãƒ³æƒ…å ±ã‚’èª­ã¿è¾¼ã‚€"""
        manifest_path = plugin_path / "plugin.json"
        
        if not manifest_path.exists():
            return None
        
        with open(manifest_path) as f:
            manifest = json.load(f)
        
        return {
            "name": manifest["name"],
            "version": manifest["version"],
            "type": manifest["type"],  # "llm", "rag", "node", etc.
            "entry_point": manifest["entry_point"],
            "path": plugin_path
        }
    
    def load_plugin(self, plugin_info: Dict[str, Any]) -> Any:
        """ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã‚’å‹•çš„ã«ãƒ­ãƒ¼ãƒ‰"""
        module_path = f"src.plugins.{plugin_info['name']}.{plugin_info['entry_point']}"
        
        try:
            module = importlib.import_module(module_path)
            return module
        except ImportError as e:
            logger.error(f"Failed to load plugin {plugin_info['name']}: {e}")
            return None

# ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆã®ä¾‹
# src/plugins/custom_llm/plugin.json
{
    "name": "custom_llm",
    "version": "1.0.0",
    "type": "llm",
    "entry_point": "provider",
    "description": "ã‚«ã‚¹ã‚¿ãƒ LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼",
    "author": "Your Name",
    "dependencies": ["openai>=1.0.0"]
}
```

```python
# src/main.pyï¼ˆæ”¹å–„ç‰ˆï¼‰
from fastapi import FastAPI
from fastapi.openapi.utils import get_openapi

app = FastAPI(
    title="LangGraph Training API",
    description="""
    LangGraphãƒ™ãƒ¼ã‚¹ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ 
    
    ## ä¸»ãªæ©Ÿèƒ½
    
    * **Atomic Workflows**: å˜ä¸€æ©Ÿèƒ½ã®åŸºæœ¬ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
    * **Composite Workflows**: è¤‡æ•°ã®Atomicã‚’çµ„ã¿åˆã‚ã›ãŸé«˜åº¦ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
    * **Node Management**: å€‹åˆ¥ãƒãƒ¼ãƒ‰ã®å®Ÿè¡Œã¨ç®¡ç†
    
    ## ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
    
    3å±¤æ§‹é€ ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼š
    - Atomic Layer: æœ€å°å®Ÿè¡Œå˜ä½
    - Composite Layer: Atomicã®çµ„ã¿åˆã‚ã›
    - Orchestration Layer: Compositeã®çµ±åˆï¼ˆä»Šå¾Œå®Ÿè£…ï¼‰
    """,
    version="2.0.0",
    contact={
        "name": "é–‹ç™ºãƒãƒ¼ãƒ ",
        "email": "team@example.com",
    },
    license_info={
        "name": "MIT",
    },
)

def custom_openapi():
    """ã‚«ã‚¹ã‚¿ãƒ OpenAPIã‚¹ã‚­ãƒ¼ãƒ"""
    if app.openapi_schema:
        return app.openapi_schema
    
    openapi_schema = get_openapi(
        title=app.title,
        version=app.version,
        description=app.description,
        routes=app.routes,
    )
    
    # ã‚¿ã‚°ã®èª¬æ˜ã‚’è¿½åŠ 
    openapi_schema["tags"] = [
        {
            "name": "workflows",
            "description": "ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"
        },
        {
            "name": "nodes",
            "description": "ãƒãƒ¼ãƒ‰ç®¡ç†ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"
        },
        {
            "name": "health",
            "description": "ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"
        }
    ]
    
    # ã‚µãƒ¼ãƒãƒ¼æƒ…å ±ã‚’è¿½åŠ 
    openapi_schema["servers"] = [
        {"url": "http://localhost:8000", "description": "é–‹ç™ºç’°å¢ƒ"},
        {"url": "https://api.example.com", "description": "æœ¬ç•ªç’°å¢ƒ"}
    ]
    
    app.openapi_schema = openapi_schema
    return app.openapi_schema

app.openapi = custom_openapi
```

```plaintext
src/
â”œâ”€â”€ frontend/              # æ–°è¦è¿½åŠ 
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ WorkflowCanvas.vue
â”‚   â”‚   â”œâ”€â”€ NodePalette.vue
â”‚   â”‚   â””â”€â”€ PropertyPanel.vue
â”‚   â”œâ”€â”€ stores/
â”‚   â”‚   â””â”€â”€ workflowStore.ts
â”‚   â””â”€â”€ App.vue
```

```yaml
# docker-compose.monitoring.yml
version: '3.8'
services:
  prometheus:
    image: prom/prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
  
  grafana:
    image: grafana/grafana
    ports:
      - "3000:3000"
    volumes:
      - ./grafana/dashboards:/etc/grafana/provisioning/dashboards
```

```python
# src/workflows/versioning.pyï¼ˆæ–°è¦ï¼‰
from typing import Dict, Any
from datetime import datetime

class WorkflowVersion:
    """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†"""
    
    def __init__(self, workflow_id: str, version: str):
        self.workflow_id = workflow_id
        self.version = version
        self.created_at = datetime.utcnow()
        self.definition: Dict[str, Any] = {}
    
    def export(self) -> Dict[str, Any]:
        """ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        return {
            "workflow_id": self.workflow_id,
            "version": self.version,
            "created_at": self.created_at.isoformat(),
            "definition": self.definition
        }
    
    @classmethod
    def from_export(cls, data: Dict[str, Any]) -> "WorkflowVersion":
        """ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å¾©å…ƒ"""
        version = cls(data["workflow_id"], data["version"])
        version.definition = data["definition"]
        return version
```

